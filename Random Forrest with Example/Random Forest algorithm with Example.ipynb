{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests is a supervised learning algorithm. It can be used both for classification and regression. It is also the most flexible and easy to use algorithm. A forest is comprised of trees. It is said that the more trees it has, the more robust a forest is. Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. It also provides a pretty good indicator of the feature importance.\n",
    "\n",
    "Random forests has a variety of applications, such as recommendation engines, image classification and feature selection. It can be used to classify loyal loan applicants, identify fraudulent activity and predict diseases. It lies at the base of the Boruta algorithm, which selects important features in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It technically is an ensemble method (based on the divide-and-conquer approach) of decision trees generated on a randomly split dataset. This collection of decision tree classifiers is also known as the forest. The individual decision trees are generated using an attribute selection indicator such as information gain, gain ratio, and Gini index for each attribute. Each tree depends on an independent random sample. In a classification problem, each tree votes and the most popular class is chosen as the final result. In the case of regression, the average of all the tree outputs is considered as the final result. It is simpler and more powerful compared to the other non-linear classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the algorithm work?\n",
    "\n",
    "It works in four steps:\n",
    "\n",
    "    Select random samples from a given dataset.\n",
    "    Construct a decision tree for each sample and get a prediction result from each decision tree.\n",
    "    Perform a vote for each predicted result.\n",
    "    Select the prediction result with the most votes as the final prediction.\n",
    "<img src = \"Random Forest.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually Decission Tree is low bias and high varience model, it means that when you build a single Decission tree upto its complete depth, it tries to learn each bit and pieces of the Training data including the error as well, but it fails to generelise on the dataset it has never seen before.\n",
    "\n",
    "So the Decission tree always has low bais and high varience which results in Overffiting of the model.\n",
    "\n",
    "The Random forrest have multiple decission trees, and each tree is given different sample and different feature set to work with, so that each tree will become so much expert that it tries to reduce the Varience and also Random forrest has a Voting classifier at the output it predicts the result based on the Majority of Votes assigned.\n",
    "Hence,\n",
    "#### Random forrest is Low Bais and Low Varience model\n",
    "\n",
    "Advantages:\n",
    "\n",
    "It overcomes the problem of overfitting by averaging or combining the results of different decision trees.    Scaling of data does not require in random forest algorithm. It maintains good accuracy even after providing   data without scaling.\n",
    "The algorithm can be used in both classification and regression problems.\n",
    "Random Forest algorithms maintains good accuracy even a large proportion of the data is missing.\n",
    "You can get the relative feature importance, which helps in selecting the most contributing features for the    classifier.\n",
    "\n",
    "Dis Advantages:\n",
    "\n",
    "Complexity is the main disadvantage of Random forest algorithms.\n",
    "More computational resources are required to implement Random Forest algorithm.\n",
    "Random forests is slow in generating predictions because it has multiple decision trees. Whenever it makes a p\n",
    "rediction, all the trees in the forest have to make a prediction for the same given input and then perform       voting on it. This whole process is time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see the implementation of Random Forrest algorithm using Python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Iris.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Id'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Iris-setosa\n",
       "1    Iris-setosa\n",
       "2    Iris-setosa\n",
       "3    Iris-setosa\n",
       "4    Iris-setosa\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "y.head()\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=50)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Accuracy: 1.0\n",
      "Test data Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "#Lets check the accuracy using predicted and actual values\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "print(\"Training data Accuracy: {}\".format(classifier.score(X_train,y_train)))\n",
    "print(\"Test data Accuracy: {}\".format(classifier.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        12\n",
      "Iris-versicolor       1.00      0.94      0.97        17\n",
      " Iris-virginica       0.94      1.00      0.97        16\n",
      "\n",
      "       accuracy                           0.98        45\n",
      "      macro avg       0.98      0.98      0.98        45\n",
      "   weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n{}\".format(classification_report(y_test,prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  0 16]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([[3,5,4,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Important Features in Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you are finding important features or selecting features in the IRIS dataset. In scikit-learn, you can perform this task in the following steps:\n",
    "\n",
    "    First, you need to create a random forests model.\n",
    "    Second, use the feature importance variable to see feature importance scores.\n",
    "    Third, visualize these scores using the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetalWidthCm     0.467580\n",
       "PetalLengthCm    0.390582\n",
       "SepalLengthCm    0.089534\n",
       "SepalWidthCm     0.052304\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_features = pd.Series(classifier.feature_importances_,index = X.columns).sort_values(ascending=False)\n",
    "imp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets visualise this with Seaborn library\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18cb159b388>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(imp_features,imp_features.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even you can remove SepalWidth feature frm the data set as it has least importance for the target variable to get good accuracy and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
